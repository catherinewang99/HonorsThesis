{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the new models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "rat_one = loadmat('Platt&Johnson1971_rat1.mat')\n",
    "rat_two = loadmat('Platt&Johnson1971_rat2.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "#def Q(ks,n,p_k,p_n,lam,sm=1e-10):\n",
    "\t#computes the posterior Q for a given lambda\n",
    "\t#q= p_k * np.exp(-(p_n/lam) * (n-ks)**2.)\n",
    "\t#q = (q+sm)/np.sum(q+sm)\n",
    "\t#return q\n",
    "\n",
    "\n",
    "\n",
    "def KL(p,q):\n",
    "\t#KL divergence with prior p and posterior q\n",
    "\treturn np.sum(q * (np.log2(q) - np.log2(p)), axis=1)\n",
    "\n",
    "\n",
    "def compute_q_nk(ns, ks, p_n,p_k, lam, sm=1e-10):\n",
    "\t#computing the posterior Q for a given lambda\n",
    "    lam = lam.reshape((len(lam),1))\n",
    "    p_n = p_n.reshape((len(p_n),1))\n",
    "\n",
    "    q_nk = -((p_n * (ns-ks)**2.)/(lam)) \n",
    "\n",
    "\n",
    "    q_nk = np.exp(q_nk)\n",
    "    q_nk = q_nk * p_k \n",
    "    \n",
    "    q_nk = q_nk/ np.sum(q_nk, axis=1).reshape(len(q_nk), 1)\n",
    "    q_nk += sm\n",
    "    q_nk = q_nk/ np.sum(q_nk, axis=1).reshape(len(q_nk), 1)\n",
    "\n",
    "\n",
    "\n",
    "    return q_nk\n",
    "\n",
    "\n",
    "def find_q_nk(ns,ks,p_n,p_k,info_bound, n_steps=1500):\n",
    "\t#uses gradient descent to find lambdas that\n",
    "\t#get KL(Q||P) as close to the bound \"info_bound\" as possible\n",
    "\n",
    "    lams = np.ones_like(ns)*0.5\n",
    "    q_nk = compute_q_nk( ns, ks, p_n,p_k, lams)\n",
    "\n",
    "    ents = KL(p_k, q_nk)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "\n",
    "        diffs = ents - info_bound\n",
    "        deltas = diffs *0.025\n",
    "\n",
    "        lams = np.exp(np.log(lams) + deltas.reshape(len(deltas),1))\n",
    "\n",
    "        q_nk = compute_q_nk(ns,ks,p_n,p_k,lams)\n",
    "        ents = KL(p_k,q_nk)\n",
    "\n",
    "    return q_nk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def P(x,a):\n",
    "\tp = 1./(x**a)\n",
    "\n",
    "\treturn p/np.sum(p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def Q(ks,n,p_k,p_n,lam,sm=1e-10):\n",
    "\t#computes the posterior Q for a given lambda\n",
    "\t#q= p_k * np.exp(-(p_n/lam) * (n-ks)**2.)\n",
    "\t#q = (q+sm)/np.sum(q+sm)\n",
    "\t#return q\n",
    "\n",
    "\n",
    "\n",
    "def KL(p,q):\n",
    "\t#KL divergence with prior p and posterior q\n",
    "\treturn np.sum(q * (np.log2(q) - np.log2(p)), axis=1)\n",
    "\n",
    "\n",
    "def compute_q_nk(ns, ks, p_n,p_k, lam, sm=1e-10):\n",
    "\t#computing the posterior Q for a given lambda\n",
    "    lam = lam.reshape((len(lam),1))\n",
    "    p_n = p_n.reshape((len(p_n),1))\n",
    "\n",
    "    q_nk = -((p_n * (ns-ks)**2.)/(lam)) \n",
    "\n",
    "\n",
    "    q_nk = np.exp(q_nk)\n",
    "    q_nk = q_nk * p_k \n",
    "    \n",
    "    q_nk = q_nk/ np.sum(q_nk, axis=1).reshape(len(q_nk), 1)\n",
    "    q_nk += sm\n",
    "    q_nk = q_nk/ np.sum(q_nk, axis=1).reshape(len(q_nk), 1)\n",
    "\n",
    "\n",
    "\n",
    "    return q_nk\n",
    "\n",
    "\n",
    "def find_q_nk(ns,ks,p_n,p_k,info_bound, n_steps=1500):\n",
    "\t#uses gradient descent to find lambdas that\n",
    "\t#get KL(Q||P) as close to the bound \"info_bound\" as possible\n",
    "\n",
    "    lams = np.ones_like(ns)*0.5\n",
    "    q_nk = compute_q_nk( ns, ks, p_n,p_k, lams)\n",
    "\n",
    "    ents = KL(p_k, q_nk)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "\n",
    "        diffs = ents - info_bound\n",
    "        deltas = diffs *0.025\n",
    "\n",
    "        lams = np.exp(np.log(lams) + deltas.reshape(len(deltas),1))\n",
    "\n",
    "        q_nk = compute_q_nk(ns,ks,p_n,p_k,lams)\n",
    "        ents = KL(p_k,q_nk)\n",
    "\n",
    "    return q_nk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def P(x,a):\n",
    "\tp = 1./(x**a)\n",
    "\n",
    "\treturn p/np.sum(p)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    info_store = []\n",
    "    four = []\n",
    "    eight = []\n",
    "    sixteen = []\n",
    "    tf = []\n",
    "    \n",
    "    for i in range(0, 21):\n",
    "\n",
    "        #step_n, step_k give increments\n",
    "        #which in our model are 1 (natural numbers)\n",
    "        step_n = 1\n",
    "        step_k = 1\n",
    "\n",
    "        #prior parameter, in our paper we use alpha = 2\n",
    "        alpha = 1\n",
    "\n",
    "        #range of n and k\n",
    "        min_n = 1\n",
    "        max_n = 15\n",
    "        min_k = step_k\n",
    "        max_k = 25\n",
    "\n",
    "    # \tks = np.arange(min_k,max_k,step_k)\n",
    "    # \tns = np.arange(min_n,max_n+1,step_n)\n",
    "    # \tns = ns.reshape((len(ns),1))\n",
    "\n",
    "        ks = np.arange(1,37)\n",
    "        ns = np.array([4,8,16,24])\n",
    "        ns = ns.reshape((len(ns),1))\n",
    "\n",
    "        p_ks = P(ks,float(alpha))\n",
    "        p_ns = P(ns,float(alpha))\n",
    "\n",
    "        info_bound = i/5\n",
    "\n",
    "        Q = find_q_nk(ns,ks,p_ns,p_ks,info_bound)\n",
    "\n",
    "        store = [sum(np.log(Q[0]) * rat_one['n4_y'][0] * 400),\n",
    "                    sum(np.log(Q[1]) * rat_one['n8_y'][0] * 400),\n",
    "                    sum(np.log(Q[2]) * rat_one['n16_y'][0] * 400),\n",
    "                    sum(np.log(Q[3]) * rat_one['n24_y'][0] * 400)]\n",
    "        info_store += [store]\n",
    "        \n",
    "        four += [sum(np.log(Q[0]) * rat_one['n4_y'][0] * 400)]\n",
    "        eight += [sum(np.log(Q[1]) * rat_one['n8_y'][0] * 400)]\n",
    "        sixteen += [sum(np.log(Q[2]) * rat_one['n16_y'][0] * 400) ]\n",
    "        tf += [sum(np.log(Q[3]) * rat_one['n24_y'][0] * 400)]\n",
    "        \n",
    "#         print(i/5)\n",
    "\n",
    "# \tprint(Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
